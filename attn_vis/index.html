<!--
Attention Visualizer based on the code of Abigail See, abisee@stanford.edu 
Originally based on code by Andrej Karpathy described here:
  http://karpathy.github.io/2015/05/21/rnn-effectiveness/
and available here:
  http://cs.stanford.edu/people/karpathy/viscode.zip
-->

<!doctype html>
<html lang="en">
 <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Attention Visualizer for Pointer-Generator Networks with Coverage</title>
  <meta name="description" content="">
  <meta name="author" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="external/d3.min.js"></script>
  <script src="external/jquery-3.1.0.min.js"></script>
  <script src="external/underscore-min.js"></script>
  <script src="external/sprintf.min.js"></script>
  <link href='https://fonts.googleapis.com/css?family=Cousine' rel='stylesheet' type='text/css'>
  <link href="https://fonts.googleapis.com/css2?family=Dela+Gothic+One&display=swap" rel="stylesheet">
  <style>
body {
  /* background: linear-gradient(#ccc, #fff); */
  font: 14px sans-serif;
  padding: 20px;
  display: flex;
  align-items:center;
  justify-content:center;
  background-color: #00203F;
  color: #00203F;
}
h1, h2 {
  font-family: 'Dela Gothic One', cursive;
  font-size-adjust: 0.58;
}
.letter {
  flex: 1;
  background: #fff;
  box-shadow: 0 0 10px rgba(0,0,0,0.3);
  margin: 26px auto 0;
  max-width: 50%;
  min-height: 300px;
  padding: 24px;
  position: relative;
  font-family: 'Cousine';
  margin: 10px;
  font-size: 15px;
  padding: 3%;
}
@media screen and (max-width: 1000px) {
  .letter {
    max-width: 90%;
  }
}
.letter:before, .letter:after {
  content: "";
  height: 98%;
  position: absolute;
  width: 100%;
  z-index: -1;
}
.letter:before {
  background: #fafafa;
  box-shadow: 0 0 8px rgba(0,0,0,0.2);
  left: -5px;
  top: 4px;
  transform: rotate(-2.5deg);
}
.letter:after {
  background: #f6f6f6;
  box-shadow: 0 0 3px rgba(0,0,0,0.2);
  right: -3px;
  top: 1px;
  transform: rotate(1.4deg);
}
.highlight-up {
  color:white; 
  font-weight:bold; 
  display:inline;
  padding: 2px;
  text-transform: uppercase;
}
  </style>
  <script>

  json_fname = "attn_vis_data.json" // file containing the text and the weights

  greenhue = 154
  redhue = 347

  function round(x, dp) {
    // round a float to dp decimal places
    var power_of_10 = 10**dp
    return Math.round(x*power_of_10)/power_of_10
  }

  function toColor(p, hue) {
    // converts a scalar value p in [0,1] to a HSL color code string with base color hue
    if (p<0 || p>1) {
      throw sprintf("Error: p has value %.2f but should be in [0,1]", p)
    }
    var saturation = 91 // saturation percentage
    p = 1-p // invert so p=0 is light and p=1 is dark
    var min_lightness = 60 // minimum percentage lightness, i.e. darkest possible color
    var lightness = (min_lightness + p*(100-min_lightness)) // lightness is proportional to p
    return sprintf('hsl(%d,%s%%,%s%%)', hue, saturation, lightness)
  }

  function render_art(div, article_lst, data, dec_idx, dec_word) {
    // render the article. if dec_idx and dec_word are not null, we highlight the article with the attention distribution for decoder timestep dec_idx and corresponding decoder word dec_word
    var startix = 0;
    var endix = article_lst.length
    var attn_len = data.attn_dists[0].length
    var dec_len = data.attn_dists.length

    div.html(''); // flush
    for(var i=startix; i<endix; i++) {
      var word = article_lst[i]; // a string
      if (dec_idx == null) {
        var attn_wt = 0;
      } else {
        var attn_wt = data.attn_dists[dec_idx][i];
      }
      var background_color = toColor(attn_wt, redhue);
      var css = 'background-color:' + background_color;
      css += ';display:inline'
      var word_html = word + ' '

      // Insert "truncated here" marker to indicate how much of the original article we actually fed into the RNN
      // Note we only have attention distribution over the portion of the article before truncation
      if (i==attn_len) {
        dnew0 = div.append('div');
        dnew0.attr('class', 'highlight-up')
          .attr('style', 'background-color: #256ADC;') // apply this style
          .html('ARTICLE TRUNCATED HERE. ');
        break
      }

      // write the sentence/word
      var dnew = div.append('div');
      dnew.attr('class', 'd')
        .attr('style', css) // apply this style
        .html(word_html)
    }
  }


  function render_dec(div, data, network_idx) {
    // render the decoded summary
    var data = data.networks_output[network_idx]
    var startix = 0;
    var endix = data.decoded_lst.length;

    div.html(''); // flush
    for(var i=startix; i<endix; i++) {
      var word = data.decoded_lst[i]; // a string
      css = 'display:inline;'
      if (data.hasOwnProperty('p_gens')) {
        var p_gen = data.p_gens[i];
        var background_color = toColor(p_gen, greenhue);
        css += 'background-color:' + background_color;
      } else {
        var p_gen = null;
      }
      var dnew = div.append('div');

      dnew.html(word+' ') // this is the content
        .attr('class', 'd')
        .attr('style', css) // apply this style
        // add interactivity for mouseover decoder words
        .on('mouseover', getHandleMouseOver(i, word, p_gen, network_idx))
        .on('mousemove', handleMouseMove)
        .on('mouseout', handleMouseOut)
    }
  }

  function getHandleMouseOver(dec_idx, dec_word, p_gen, network_idx) {
     // When you mouseover a decoder word, shows attention distribution on article
     // p_gen is null for non-pointer models
    return function() {
      // Renders the article with the appropriate highlighting
      render_art(d3.select('#art'), gdata.article_lst, gdata.networks_output[network_idx], dec_idx, dec_word);
      // Show a tooltip giving value of p_gen
      if (p_gen != null) {
        gtooltip.text(`p_gen = ${round(p_gen, 3)}`)
        return gtooltip.style("visibility", "visible");
      }
    }
  }

  function handleMouseMove() {
    // When you move cursor over a decoder word, tooltip shows value of generation probability for that word
    return gtooltip.style("top", (d3.event.pageY-20)+"px").style("left",(d3.event.pageX+10)+"px");
  }

  function handleMouseOut() {
    // When you move cursor away from a decoder word, stop showing generation probability tooltip
    return gtooltip.style("visibility", "hidden");
  }

  function get_json_and_disp() {
    // Retrieve the json data file and display the data
    console.log("fetching " + json_fname + "...")

    function json_success(data) {
      // Displays the data
      console.log("success!")
      d3.select("#header_mark").html("<h1>Visualize summary, attention and the probability of generation on your own content ‚úçÔ∏è</h1>")
      gdata = data; // store globally
      render_art(d3.select("#art"), gdata.article_lst, gdata.networks_output[0], null, null);
      render_dec(d3.select("#dec-s2s"), gdata, 0);
      render_dec(d3.select("#dec-pgen"), gdata, 1);
      render_dec(d3.select("#dec-pgen_cov"), gdata, 2);
    }

    function json_fail(d) {
      // Tell the user it failed to load
      console.log("failure.")
      d3.select("#header_mark").html('<font color="red">Failed to load ' + json_fname + "</font>")
    }

    $.getJSON(json_fname, json_success).fail(json_fail);
  }

  function start() {
    console.log("start")
    get_json_and_disp()

    // Define a tooltip that we will use to display generation probability of a decoder word when you hover over it
    var tooltip = d3.select("body")
        .append("div")
        .style("position", "absolute")
        .style("z-index", "10")
        .style("visibility", "hidden")
        .style("background", "white")
        .style("font-size", "15px")
        .style("font-family", "Cousine")
        .text("a simple tooltip");
    gtooltip = tooltip // global
  }

  </script>
  </head>
  <body onload="start();">
    <div class="letter">
      <div id="header_mark">
        Current datafile name goes here.
      </div>
      <p>üí° Hint: Use <code>CTRL + -</code> or <code>CMD + -</code> to zoom out if the text is large!</p>
      <h2>Original content</h2>
      <div id="art">
        article goes here
      </div>
      <br>
      <h2>1. Summary with base Seq2Seq architecture with attention</h2>
      <div id="dec-s2s">
        generated summary goes here
      </div>
      <h2>2. Summary with Seq2Seq, attention and pointer-generator system</h2>
      <div id="dec-pgen">
        generated summary goes here
      </div>
      <h2>3. Summary with Seq2Seq, attention, pointer-generator, and coverage mechanism</h2>
      <div id="dec-pgen_cov">
        generated summary goes here
      </div>
      <h2>A few notes</h2>
      <p>
        The amount of attention ported to the words from the source content is reported in <span class="highlight-up"
          style="background-color: hsl(347,91%,60%)">RED</span>, and is different for all the decoded summaries. All tokens between two "__" are out of the base vocabulary.
      </p>
      <p>
        The text before the truncation in <span class="highlight-up" style="background-color: #256ADC">BLUE</span> was passed
        as input to the networks with respect to the <code>max_words_input</code> parameter.
      </p>
      <p>The value of p_gen, being high when generating words from the base vocabulary and low when pointing to the source
        content,
        is showed in the decoded summaries in <span class="highlight-up"
          style="background-color: hsl(154,91%,60%)">GREEN</span>.</p>
    </div>
  </body>
</html>
